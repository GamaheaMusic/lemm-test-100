# üéµ Music Generation App - Changelog

## üîß Latest Update (December 11, 2025) - **Music Generation Fixes**

### **Fixed DiffRhythm 2 Model Loading & Added AMD GPU Support** üöÄ

#### Critical Fixes:
- **Fixed music generation** - Was producing only a tone due to missing dependencies
- **Added missing Python packages** - torchdiffeq, pykakasi, unidecode, py3langid
- **Fixed transformers version** - Pinned to 4.47.1 for DiffRhythm2 compatibility
- **Added AMD GPU support** - torch-directml for AMD/Intel GPUs (Python 3.11)

#### Technical Changes:
1. **Dependency Updates**
   - Added `torchdiffeq>=0.2.4` - Required for CFM (flow matching)
   - Added `pykakasi>=2.3.0` - Japanese text processing
   - Added `unidecode>=1.3.0` - Text normalization
   - Added `py3langid>=0.2.2` - Language detection
   - Pinned `transformers==4.47.1` - Newer versions break DiffRhythm2
   - Added `torch-directml` support for Python 3.11 (AMD GPUs)

2. **Device Selection Enhancement**
   - Priority: CUDA (NVIDIA) ‚Üí DirectML (AMD/Intel) ‚Üí CPU
   - Automatic GPU detection and selection
   - DirectML requires Python 3.11

3. **Model Loading Fixed**
   - DiffRhythm2 modules now load correctly
   - All dependencies resolved
   - Model downloads from HuggingFace on first use

#### Files Modified:
- ‚úÖ `requirements.txt` - Added missing dependencies, AMD GPU support
- ‚úÖ `backend/services/diffrhythm_service.py` - Enhanced device detection
- üÜï `MUSIC_GEN_FIX.md` - Troubleshooting guide

#### Expected Behavior:
- ‚úÖ DiffRhythm2 model loads successfully
- ‚úÖ Music generation takes 30-120 seconds (not instant)
- ‚úÖ Output is actual music (not a tone)
- ‚úÖ Vocals included if lyrics provided
- ‚úÖ AMD GPU support via DirectML (Python 3.11)

---

## üöÄ Previous Update - **DiffRhythm 2 Integration**

### **Replaced MusicGen with DiffRhythm 2** üé∂

#### Major Changes:
- **Replaced MusicGen with actual DiffRhythm 2** - Full text-to-music-with-vocals model
- **Native vocal synthesis** - No separate TTS needed, vocals generated with instrumentals
- **Lyrics-to-phoneme pipeline** - Uses g2p tokenization for accurate pronunciation
- **Style-conditioned generation** - MuQ-MuLan model encodes prompt for genre/mood
- **Complete rewrite** - `diffrhythm_service.py` now uses real DiffRhythm 2 from ASLP-lab

#### Technical Details:
1. **DiffRhythm 2 Architecture**
   - CFM (Conditional Flow Matching) backbone
   - DiT (Diffusion Transformer) for latent generation
   - BigVGAN vocoder for audio synthesis
   - MuQ-MuLan for style encoding from text prompts
   - g2p tokenizer for lyrics ‚Üí phonemes

2. **Installation Requirements**
   - espeak-ng (system package) - Required for phonemization
   - phonemizer>=3.2.0 - Python wrapper for espeak
   - DiffRhythm 2 from GitHub (auto-installs)
   - Models download from HuggingFace: `ASLP-lab/DiffRhythm2`

3. **New Features**
   - Structure tags: [start], [verse], [chorus], [bridge], [stop]
   - Supports Chinese and English lyrics
   - CFG scale control (default: 2.0)
   - Adjustable sampling steps (default: 16)
   - Fake stereo effect for mono outputs

#### Files Modified:
- ‚úÖ `requirements.txt` - Added DiffRhythm 2 dependencies (phonemizer, muq, etc.)
- ‚úÖ `backend/services/diffrhythm_service.py` - Complete rewrite (~405 lines)
- üÜï `INSTALL_DIFFRHYTHM2.md` - Installation guide for DiffRhythm 2
- üÜï `test_diffrhythm2.py` - Test script to verify installation

---

## üîÑ Previous Update - **Removed Fish Speech - Integrated Vocals into DiffRhythm** üé§

#### What Changed:
- **Removed Fish Speech service** - DiffRhythm now handles both instrumentals AND vocals
- **Added prompt analysis utility** - Automatically extracts genre, BPM, mood, and style from prompts
- **Improved lyrics generation** - Now uses prompt analysis for more accurate/appropriate lyrics
- **Streamlined workflow** - Single generation step instead of separate music + vocals mixing

#### Key Improvements:
1. **Prompt Analysis** (`backend/utils/prompt_analyzer.py`)
   - Automatically detects: genre, BPM, mood, instruments, style tags
   - Analysis shared between DiffRhythm and LyricsMind for consistency
   - Better context for AI models = better results

2. **Updated DiffRhythm Service**
   - Now accepts `lyrics` parameter
   - Combines prompt + lyrics in single generation
   - Generates music with vocals in one step

3. **Enhanced LyricsMind Service**
   - Uses prompt analysis for context-aware lyrics
   - Automatically adapts to detected genre/mood
   - More accurate lyrics that match the music style

4. **API Changes**
   - Added `auto_lyrics` flag - automatically generates lyrics if vocals enabled
   - Returns analysis data with each generation
   - Removed Fish Speech endpoints and service

5. **Frontend Updates**
   - Auto-generates lyrics when vocals enabled but no lyrics provided
   - Displays generated lyrics in UI
   - Updated help text to reflect DiffRhythm vocal generation

#### Files Modified:
- ‚úÖ `backend/services/diffrhythm_service.py` - Added lyrics parameter
- ‚úÖ `backend/services/lyricmind_service.py` - Integrated prompt analysis
- ‚úÖ `backend/routes/generation.py` - Removed Fish Speech, added auto-lyrics
- ‚úÖ `backend/models/schemas.py` - Added `auto_lyrics` field
- ‚úÖ `backend/config/settings.py` - Removed Fish Speech model path
- ‚úÖ `backend/services/__init__.py` - Removed Fish Speech import
- ‚úÖ `frontend/js/app.js` - Added auto-lyrics support
- ‚úÖ `frontend/index.html` - Updated vocal checkbox label
- üÜï `backend/utils/prompt_analyzer.py` - NEW prompt analysis utility

#### Files Deprecated:
- ‚ùå `backend/services/fish_speech_service.py` - No longer used (can be deleted)

---

## ‚úÖ Previous Updates

### 1. **Replaced Web GUI with Gradio** ‚ú®
- Modern, responsive Gradio interface
- Easier to use than the original HTML/CSS/JS frontend
- Built-in audio player and download features
- Accessible at http://localhost:7860

### 2. **Added AMD GPU Support** üéÆ
- Integrated DirectML for AMD GPU acceleration
- Optimized for AMD Vega 8 (your GPU)
- Automatic CPU fallback if GPU unavailable
- **Note**: Python 3.13 may not support DirectML - app uses CPU mode

### 3. **Local Model Installation** üì•
- Created `setup_models.py` to download models locally
- Models stored in `models/` folder
- No cloud API dependencies
- Models used:
  - **MusicGen-small** (~1.5GB) - Music generation
  - **Phi-2** (~5GB) - Lyrics generation
  - **Fish Speech** (~2GB) - Vocal synthesis

### 4. **Updated Dependencies** üì¶
- Removed Flask (no longer needed)
- Added Gradio for UI
- Added torch-directml for AMD GPU
- Added transformers, huggingface-hub for AI models
- All audio processing libraries updated

## üìÇ New/Updated Files

### Main Application
- `app_gradio.py` - New Gradio interface (replaces Flask backend + HTML frontend)
- `setup_models.py` - Model download script
- `test_setup.py` - System verification script

### Scripts
- `start_app.ps1` / `start_app.bat` - Launch Gradio app
- `setup_models.ps1` / `setup_models.bat` - Download models

### Backend Updates
- `backend/services/diffrhythm_service.py` - Added MusicGen integration + AMD GPU
- `backend/services/lyricmind_service.py` - Added Phi-2 integration + AMD GPU
- `backend/services/fish_speech_service.py` - Added AMD GPU support
- `backend/utils/amd_gpu.py` - **NEW** - AMD GPU detection & configuration

### Configuration
- `.env` - Updated for Gradio and DirectML
- `requirements.txt` - Updated with new dependencies
- `README.md` - Completely rewritten for Gradio app
- `QUICKSTART.md` - **NEW** - Quick start guide
- `AMD_GPU_INFO.md` - **NEW** - AMD GPU information

## üöÄ How to Use

### First Time Setup

1. **Download Models** (required first time):
   ```powershell
   .\setup_models.ps1
   ```
   This downloads ~8-9GB of AI models.

2. **Start the App**:
   ```powershell
   .\start_app.ps1
   ```

3. **Open Browser**: http://localhost:7860

### Creating Music

1. **Generate Music** tab:
   - Enter prompt: "upbeat electronic music"
   - Optional: Click "Auto Generate Lyrics"
   - Set duration (10-120 seconds)
   - Choose timeline position
   - Click "Generate Music Clip"

2. **Timeline** tab:
   - View all clips
   - Remove clips
   - Clear timeline

3. **Export** tab:
   - Enter filename
   - Choose format (WAV/MP3/FLAC)
   - Click "Export Timeline"
   - Download your song!

## ‚öôÔ∏è Current System Status

### Working Features ‚úÖ
- ‚úÖ Gradio interface
- ‚úÖ Music generation (MusicGen)
- ‚úÖ Lyrics generation (Phi-2)
- ‚úÖ Timeline management
- ‚úÖ Export to multiple formats
- ‚úÖ CPU processing (fast enough)

### GPU Status ‚ö†Ô∏è
- **DirectML**: Not compatible with Python 3.13
- **Current Mode**: CPU (functional, slower)
- **To Enable GPU**: Use Python 3.11 (see AMD_GPU_INFO.md)

### Models Status üì•
- **Not yet downloaded** - Run `setup_models.ps1` first
- **Download size**: ~8-9 GB
- **Storage location**: `models/` folder
- **One-time download**: Models cached locally

## üìä Performance Expectations

### CPU Mode (Current)
- Music generation: 1-3 minutes per 30s clip
- Lyrics generation: 20-60 seconds
- First run: ~60 seconds (model loading)
- Subsequent runs: 60-180 seconds

### With AMD GPU (Python 3.11 + DirectML)
- Music generation: 15-30 seconds per 30s clip
- Lyrics generation: 5-10 seconds
- First run: ~20 seconds (model loading)
- Subsequent runs: 15-30 seconds

## üîß Troubleshooting

### App Won't Start
```powershell
# Activate environment
.\.venv\Scripts\Activate.ps1

# Start manually
python app_gradio.py
```

### Models Not Found
```powershell
# Run model setup
python setup_models.py
```

### Check System Status
```powershell
python test_setup.py
```

## üìù Important Notes

1. **Models are required**: Run `setup_models.ps1` before first use
2. **Internet needed**: Only for first-time model download
3. **Storage**: Need ~10GB free space for models
4. **CPU mode works fine**: GPU is optional (just faster)
5. **Python 3.13 limitation**: DirectML not compatible yet

## üéØ Next Steps

### Immediate (Required)
1. Run `.\setup_models.ps1` to download AI models
2. Run `.\start_app.ps1` to launch the app
3. Create your first song!

### Optional (For Better Performance)
1. Read `AMD_GPU_INFO.md` about GPU support
2. Consider Python 3.11 environment for GPU acceleration
3. Experiment with different prompts and styles

## üìö Documentation

- **QUICKSTART.md** - Step-by-step getting started
- **README.md** - Complete documentation
- **AMD_GPU_INFO.md** - AMD GPU information
- **.env** - Configuration settings

## üÜò Need Help?

1. Check `logs/app.log` for errors
2. Run `python test_setup.py` to verify setup
3. Read QUICKSTART.md for step-by-step guide
4. Check AMD_GPU_INFO.md for GPU questions

---

## Summary

‚úÖ **Gradio GUI**: Replaced HTML/CSS/JS with modern Gradio interface
‚úÖ **AMD GPU Support**: Added DirectML (requires Python 3.11)
‚úÖ **Local Models**: Downloads models locally, no cloud APIs
‚úÖ **Ready to Use**: Just download models and start!

**Current Status**: CPU mode (functional) - Run `setup_models.ps1` to get started!
